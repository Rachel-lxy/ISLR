---
title: "Chapter 7 Lab"
author: "Xinyu Li"
date: "January 25, 2017"
output: html_document
---

```{r cars}
library(ISLR)
attach(Wage)
```

## 7.8.1 Polynomial Regression and Step Functions

'poly' returns a matrix whose columns are a basis of orthogonal polynomials, which essentially means that each column is a linear orthogonal combination of the variables age, age^2, age^3 and age^4.
```{r}
fit = lm(wage~poly(age,4), data=Wage)
coef(summary(fit))
```

We can use raw=TRUE to obtain age, age^2, age^3 and age^4 directly.
```{r}
fit2 = lm(wage~poly(age,4,raw=T), data=Wage)
coef(summary(fit2))
```

Use I(age) to fit this model.
```{r}
fit2a = lm(wage~age+I(age^2)+I(age^3)+I(age^4), data=Wage)
coef(fit2a)
fit2b = lm(wage~cbind(age, age^2, age^3, age^4), data=Wage)
coef(fit2b)
```

```{r}
agelims = range(age)
age.grid = seq(from=agelims[1], to=agelims[2])
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
preds2 = predict(fit2, newdata=list(age=age.grid), se=TRUE)
max(abs(preds$fit - preds2$fit))
se.bands = cbind(preds$fit + 2*preds$se.fit, preds$fit - 2*preds$se.fit) # the confidence interval
```

Hypothesis test to determine whether a more complex model is needed.
```{r}
fit.1 = lm(wage~age, data=Wage)
fit.2 = lm(wage~poly(age,2), data=Wage)
fit.3 = lm(wage~poly(age,3), data=Wage)
fit.4 = lm(wage~poly(age,4), data=Wage)
fit.5 = lm(wage~poly(age,5), data=Wage)
anova(fit.1, fit.2, fit.3, fit.4, fit.5) # Analysis of Variance Table
```

```{r}
# the square of t-statistics are equal to the F-statistics from the anova() function
coef(summary(fit.5))
```

Use anova to compare different type of models
```{r}
fit.1 = lm(wage~education+age, data=Wage)
fit.2 = lm(wage~education+poly(age,2), data=Wage)
fit.3 = lm(wage~education+poly(age,3), data=Wage)
anova(fit.1, fit.2, fit.3)
```

Predict whether an individual earns more than $250,000 per year
```{r}
fit = glm(I(wage>250)~poly(age,4), data=Wage, family=binomial)
# prediction of probability directly
preds = predict(fit, newdata=list(age=age.grid), type="response", se=T)
# prediction of logistic regression with logit value to create sensible confidence intervals
preds = predict(fit, newdata=list(age=age.grid), se=T) 
pfit = exp(preds$fit)/(1+exp(preds$fit))
se.bands.logit = cbind(preds$fit+2*preds$se.fit, preds$fit-2*preds$se.fit)
se.bands = exp(se.bands.logit)/(1+exp(se.bands.logit))
```

Figure 7.1
```{r}
par(mfrow=c(1,2), mar=c(4.5,4.5,1,1), oma=c(0,0,4,0))
plot(age, wage, xlim=agelims, cex=.5, col="darkgrey")
title("Degree-4 Polynomial", outer=T)
lines(age.grid, preds$fit, lwd=2, col="blue")
matlines(age.grid, se.bands, lwd=1, col="blue", lty=3)
plot(age, I(wage>250), xlim=agelims, type="n", ylim=c(0,.2))
points(jitter(age), I((wage>250)/5), cex=.5, pch="|", col="darkgrey")
lines(age.grid, pfit, lwd=2, col="blue")
matlines(age.grid, se.bands, lwd=1, col="blue", lty=3)
```

```{r}
table(cut(age,4))
fit = lm(wage~cut(age,4), data=Wage)
coef(summary(fit))
```

## 7.8.2 Splines

Fit wage to age using a regression spline. By default, cubic splines are produced. 
```{r}
library(splines)
fit = lm(wage~bs(age, knots=c(25,40,60)), data=Wage)
pred = predict(fit, newdata=list(age=age.grid), se=T)
```

Produce a spline with knots at uniform quantiles of the data
```{r}
dim(bs(age,knots=c(25,40,60)))
dim(bs(age,df=6))
attr(bs(age,df=6), "knots")
```

Fit a natural spline
```{r}
fit2 = lm(wage~ns(age,df=4), data=Wage)
pred2 = predict(fit2, newdata=list(age=age.grid), se=T)
```

Plot the spline and natural spline
```{r}
plot(age, wage, col="gray")
lines(age.grid, pred$fit, lwd=2)
lines(age.grid, pred$fit+2*pred$se, lty="dashed")
lines(age.grid, pred$fit-2*pred$se, lty="dashed")
lines(age.grid, pred2$fit, col="red", lwd=2)
```

Fit a smoothing spline
```{r}
fit = smooth.spline(age, wage, df=16)
fit2 = smooth.spline(age, wage, cv=TRUE)
fit2$df
plot(age, wage, xlim=agelims, cex=.5, col="darkgrey")
title("Smoothing Spline")
lines(fit, col="red", lwd=2)
lines(fit2, col="blue", lwd=2)
legend("topright", legend=c("16 DF","6.8 DF"), col=c("red","blue"), lty=1, lwd=2, cex=.8)
```

Fit a local regression
```{r}
fit = loess(wage~age, span=.2, data=Wage)
fit2 = loess(wage~age, span=.5, data=Wage)
plot(age, wage, xlim=agelims, cex=.5, col="darkgrey")
title("Local Regression")
lines(age.grid, predict(fit, data.frame(age=age.grid)), col="red", lwd=2)
lines(age.grid, predict(fit2, data.frame(age=age.grid)), col="blue", lwd=2)
legend("topright", legend=c("Span=0.2","Span=0.5"), col=c("red","blue"), lty=1, lwd=2, cex=.8)
```

## 7.8.3 GAMs
```{r}
gam1 = lm(wage~ns(year,4)+ns(age,5)+education, data=Wage)
library(gam)
gam.m3 = gam(wage~s(year,4)+s(age,5)+education, data=Wage) # s takes degrees of freedom as argument
par(mfrow=c(1,3))
plot.gam(gam1, se=TRUE, col="red")
par(mfrow=c(1,3))
plot(gam.m3, se=TRUE, col="blue")
```

```{r}
gam.m1 = gam(wage~s(age,5)+education, data=Wage)
gam.m2 = gam(wage~year+s(age,5)+education, data=Wage)
preds = predict(gam.m2, newdata=Wage)
anova(gam.m1, gam.m2, gam.m3, test="F")

# The p-values for year and age correspond to a null hypothesis of a linear relationship versus the alternative of a non-linear relationship
summary(gam.m3)
```

```{r}
gam.lo = gam(wage~s(year,df=4)+lo(age,span=.7)+education, data=Wage)
par(mfrow=c(1,3))
plot(gam.lo, se=TRUE, col="green")
```

```{r}
gam.lo.i = gam(wage~lo(year,age,span=.5)+education, data=Wage)
library(akima)
par(mfrow=c(1,2))
plot(gam.lo.i)
```

```{r}
gam.lr = gam(I(wage>250)~year+s(age,df=5)+education, family=binomial, data=Wage)
table(education, I(wage>250))
par(mfrow=c(1,3))
plot(gam.lr, se=T, col="green")
gam.lr.s = gam(I(wage>250)~year+s(age,5)+education, family=binomial, data=Wage,
               subset=(education!="1. < HS Grad"))
par(mfrow=c(1,3))
plot(gam.lr.s, se=T, col="green")
```